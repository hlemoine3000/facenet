[Modes]

eval_lfw = true
eval_cox = false

save_lfw_projections = false
save_cox_projections = false

# Performs random cropping of training images. If false, the center image_size pixels from the training images are used.
# If the size of the images in the data directory is equal to image_size no cropping is performed.
random_crop=False
# Performs random horizontal flipping of training images.
random_flip=False

[Hyper parameters]

# Random seed.
seed=666

# Positive to negative triplet distance margin.
alpha=0.2
# Triplet loss weight
zeta=1.0

# Number of images to process in a batch.
batch_size=72
# Dimensionality of the embedding.
embedding_size=128
# Number of batches per epoch.
epoch_size=1000
# Number of epochs to run.
max_nrof_epochs=100
# Image size (height, width) in pixels.
image_size=160
# Number of images per person.
images_per_person=5
# Number of people per batch. (720)
people_per_batch=100
# Keep probability of dropout for the fully connected layer(s).
keep_probability=1.0
# L2 weight regularization.
weight_decay=2e-4
# The optimization algorithm to use
# ADAGRAD, ADADELTA, ADAM, RMSPROP, MOM
optimizer=ADAGRAD
# Initial learning rate. If set to a negative value a learning rate
# schedule can be specified in the file learning_rate_schedule.txt
learning_rate=0.001
# Number of epochs between learning rate decay.
learning_rate_decay_epochs=4
# Learning rate decay factor.
learning_rate_decay_factor=0.98

# Exponential decay for tracking of training parameters.
moving_average_decay=0.9999

# Number of folds to use for cross validation. Mainly used for testing.
nrof_folds=10

gpu_memory_fraction=1.0

max_emb_per_subject = 10
max_subjects = 10


[Data directory]

# Could be either a directory containing the meta_file and ckpt_file or a model protobuf (.pb) file
pretrained_model = /export/livia/data/lemoineh/facenet/models/test_1/model-20180917-150357.ckpt-500131
model_def = src.models.inception_resnet_v2

models_base_dir=/export/livia/data/lemoineh/facenet/test_quad/models
logs_base_dir=/export/livia/data/lemoineh/facenet/test_quad/logs

# File containing the learning rate schedule that is used when learning_rate is set to to -1.
learning_rate_schedule_file='data/learning_rate_schedule.txt'

#VGGface2
vggface2_train_dir=/export/livia/data/lemoineh/vggface2/train_182
vggface2_val_dir=/export/livia/data/lemoineh/vggface2/test_182

#LFW
# Path to the data directory containing aligned LFW face patches.
lfw_dir = /export/livia/data/lethanh/lfw/lfw_mtcnnpy_160
# The file containing the LFW pairs to use for validation.
lfw_pairs = data/pairs.txt
# The file containing the LFW subjects for embeddings projection.
lfw_projection = data/lfw_projection.txt

# COX-S2V
# Path to the COX subject list.
cox_subject_list = data/cox/cox_subject_list.txt
# Path to the data directory containing aligned COX still face patches.
cox_still_dir = /export/livia/data/lemoineh/COX-S2V/COX-S2V-Still-MTCNN160
# Path to the data directory containing aligned COX video face patches.
cox_video_dir = /export/livia/data/lemoineh/COX-S2V/COX-S2V-Video-MTCNN160
source_videos = video1,video2
target_videos = video3,video4
#cox_video_name = video1,video2,video4
# The file containing the COX pairs to use for validation.
cox_pairs = data/cox
# The file containing the COX subjects for embeddings projection.
cox_projection = data/cox/cox_projection.txt

# Chokepoint
chokepoint_still_dir = /export/livia/data/lemoineh/ChokePoint/Stills/edit_train_160
chokepoint_video_dir = /export/livia/data/lemoineh/ChokePoint/train_rgb
chokepoint_pairs = data/chokepoint_rgb_pairs.txt
